# Face Aging Model Training Configuration

# Model Configuration
model:
  type: "caae"  # Options: caae, gan, basic
  input_channels: 3
  latent_dim: 100
  num_age_classes: 3
  image_size: 256

# Data Configuration
data:
  data_dir: "data/processed"
  metadata_path: "data/processed/dataset_metadata.json"
  batch_size: 16
  num_workers: 4
  target_size: [256, 256]
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1

# Training Configuration
training:
  epochs: 100
  learning_rate: 0.001
  optimizer: "adam"  # Options: adam, sgd, adamw
  weight_decay: 0.0001
  gradient_clip: 1.0
  
  # Learning rate scheduler
  scheduler: "cosine"  # Options: step, cosine, None
  scheduler_step_size: 30
  scheduler_gamma: 0.1
  
  # Loss weights for CAAE
  lambda_recon: 10.0
  lambda_age: 1.0
  lambda_adv: 1.0
  
  # Separate learning rates for CAAE
  ae_learning_rate: 0.001
  d_learning_rate: 0.0002

# Logging and Checkpointing
logging:
  log_dir: "logs"
  checkpoint_dir: "checkpoints"
  save_frequency: 10
  use_wandb: false
  wandb_project: "face-aging-model"

# Hardware Configuration
hardware:
  device: "auto"  # Options: auto, cuda, cpu
  mixed_precision: false
  num_gpus: 1

# Evaluation Configuration
evaluation:
  eval_frequency: 5
  save_samples: true
  num_samples: 8

# Data Augmentation
augmentation:
  horizontal_flip: true
  random_rotation: 10
  brightness_contrast: 0.3
  hue_saturation: 0.3
  gaussian_noise: 0.2

# Model-specific configurations
caae:
  encoder_channels: [64, 128, 256, 512, 512]
  decoder_channels: [512, 256, 128, 64, 3]
  discriminator_channels: [64, 128, 256, 512]

gan:
  generator_channels: [512, 256, 128, 64, 3]
  discriminator_channels: [64, 128, 256, 512]
  latent_dim: 100
  conditional: true 